{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks for Pima Indian dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import data\n",
    "from model import MLP\n",
    "import tensorflow as tf\n",
    "import helper\n",
    "import itertools\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import SparsePCA\n",
    "seed=1\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5.0\n"
     ]
    }
   ],
   "source": [
    "#TensorFlow version\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve imputed train and test sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "currentPath = os.getcwd()\n",
    "test_list = data.testImputed(currentPath=currentPath)\n",
    "train = data.trainImputed(currentPath=currentPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split Outcome into two columns instead of 1: Diabetic and Not_Diabetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For train\n",
    "train[\"Not Diabetic\"] = (train[\"Outcome\"] == 0).astype(int)\n",
    "train.rename(columns={\"Outcome\": \"Diabetic\"}, inplace=True)\n",
    "\n",
    "#For test\n",
    "for i in range(len(test_list)):\n",
    "    test_list[i][\"Not Diabetic\"] = (test_list[i][\"Outcome\"] == 0).astype(int)\n",
    "    test_list[i].rename(columns={\"Outcome\": \"Diabetic\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into target and features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.as_matrix()[:,0:-2]\n",
    "y_train = train.as_matrix()[:, -2:]\n",
    "test_split_list = list()\n",
    "\n",
    "#First element is X, second element is y\n",
    "for i in range(len(test_list)):\n",
    "    test_split_list.append( [ test_list[i].as_matrix()[:,0:-2],\n",
    "                         test_list[i].as_matrix()[:,-2:] ] )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_split_list[0][0]\n",
    "y_test = test_split_list[0][1]\n",
    "scale_X = StandardScaler()\n",
    "scale_X.fit(X_train)\n",
    "X_train_scaled = scale_X.transform(X_train)\n",
    "X_test_scaled = scale_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Run: Initiate and train a Multi-layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputDim = X_train_scaled.shape[1]\n",
    "outputDim = y_train.shape[1]\n",
    "mlp = MLP()\n",
    "mlp.buildModel(neurons=[10,10,10,10], activations=[\"relu\", \"relu\", \"relu\", \"relu\"], \n",
    "               dropout=[0.5,0.5,0.5,0.5], inputDim=inputDim, outputDim=outputDim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 : Training loss: 0.70648676157, \n",
      " test accuracy : 0.342857152224\n",
      "\n",
      "Epoch 11 : Training loss: 0.702401518822, \n",
      " test accuracy : 0.342857152224\n",
      "\n",
      "Epoch 21 : Training loss: 0.70127260685, \n",
      " test accuracy : 0.342857152224\n",
      "\n",
      "Epoch 31 : Training loss: 0.703016161919, \n",
      " test accuracy : 0.342857152224\n",
      "\n",
      "Epoch 41 : Training loss: 0.69585609436, \n",
      " test accuracy : 0.342857152224\n",
      "\n",
      "Epoch 51 : Training loss: 0.695337116718, \n",
      " test accuracy : 0.657142877579\n",
      "\n",
      "Epoch 61 : Training loss: 0.685764968395, \n",
      " test accuracy : 0.657142877579\n",
      "\n",
      "Epoch 71 : Training loss: 0.682702302933, \n",
      " test accuracy : 0.657142877579\n",
      "\n",
      "Epoch 81 : Training loss: 0.686173856258, \n",
      " test accuracy : 0.657142877579\n",
      "\n",
      "Epoch 91 : Training loss: 0.68150472641, \n",
      " test accuracy : 0.657142877579\n",
      "\n",
      "Epoch 101 : Training loss: 0.672257125378, \n",
      " test accuracy : 0.657142877579\n",
      "\n",
      "Epoch 111 : Training loss: 0.668359220028, \n",
      " test accuracy : 0.657142877579\n",
      "\n",
      "Epoch 121 : Training loss: 0.652190566063, \n",
      " test accuracy : 0.657142877579\n",
      "\n",
      "Epoch 131 : Training loss: 0.654684960842, \n",
      " test accuracy : 0.657142877579\n",
      "\n",
      "Epoch 141 : Training loss: 0.639796972275, \n",
      " test accuracy : 0.657142877579\n",
      "\n",
      "Epoch 151 : Training loss: 0.66395586729, \n",
      " test accuracy : 0.657142877579\n",
      "\n",
      "Epoch 161 : Training loss: 0.629236578941, \n",
      " test accuracy : 0.657142877579\n",
      "\n",
      "Epoch 171 : Training loss: 0.651956439018, \n",
      " test accuracy : 0.657142877579\n",
      "\n",
      "Epoch 181 : Training loss: 0.637801587582, \n",
      " test accuracy : 0.657142877579\n",
      "\n",
      "Epoch 191 : Training loss: 0.666927814484, \n",
      " test accuracy : 0.657142877579\n",
      "\n",
      "Epoch 201 : Training loss: 0.634997963905, \n",
      " test accuracy : 0.657142877579\n",
      "\n",
      "Epoch 211 : Training loss: 0.63240468502, \n",
      " test accuracy : 0.657142877579\n",
      "\n",
      "Epoch 221 : Training loss: 0.65698581934, \n",
      " test accuracy : 0.657142877579\n",
      "\n",
      "Epoch 231 : Training loss: 0.600256979465, \n",
      " test accuracy : 0.657142877579\n",
      "\n",
      "Epoch 241 : Training loss: 0.582064807415, \n",
      " test accuracy : 0.657142877579\n",
      "\n",
      "Epoch 251 : Training loss: 0.632732450962, \n",
      " test accuracy : 0.657142877579\n",
      "\n",
      "Epoch 261 : Training loss: 0.610587060452, \n",
      " test accuracy : 0.657142877579\n",
      "\n",
      "Epoch 271 : Training loss: 0.593069732189, \n",
      " test accuracy : 0.657142877579\n",
      "\n",
      "Epoch 281 : Training loss: 0.582041501999, \n",
      " test accuracy : 0.657142877579\n",
      "\n",
      "Epoch 291 : Training loss: 0.614672780037, \n",
      " test accuracy : 0.657142877579\n",
      "\n",
      "Epoch 301 : Training loss: 0.623591780663, \n",
      " test accuracy : 0.657142877579\n",
      "\n",
      "Epoch 311 : Training loss: 0.589031875134, \n",
      " test accuracy : 0.657142877579\n",
      "\n",
      "Epoch 321 : Training loss: 0.53081035614, \n",
      " test accuracy : 0.657142877579\n",
      "\n",
      "Epoch 331 : Training loss: 0.604298353195, \n",
      " test accuracy : 0.657142877579\n",
      "\n",
      "Epoch 341 : Training loss: 0.553157031536, \n",
      " test accuracy : 0.657142877579\n",
      "\n",
      "Epoch 351 : Training loss: 0.607506930828, \n",
      " test accuracy : 0.657142877579\n",
      "\n",
      "Epoch 361 : Training loss: 0.602309048176, \n",
      " test accuracy : 0.657142877579\n",
      "\n",
      "Epoch 371 : Training loss: 0.550845980644, \n",
      " test accuracy : 0.657142877579\n",
      "\n",
      "Epoch 381 : Training loss: 0.53530728817, \n",
      " test accuracy : 0.657142877579\n",
      "\n",
      "Epoch 391 : Training loss: 0.530287563801, \n",
      " test accuracy : 0.814285695553\n",
      "\n",
      "Epoch 401 : Training loss: 0.509501218796, \n",
      " test accuracy : 0.800000011921\n",
      "\n",
      "Epoch 411 : Training loss: 0.655608475208, \n",
      " test accuracy : 0.800000011921\n",
      "\n",
      "Epoch 421 : Training loss: 0.52397531271, \n",
      " test accuracy : 0.771428585052\n",
      "\n",
      "Epoch 431 : Training loss: 0.580105960369, \n",
      " test accuracy : 0.757142841816\n",
      "\n",
      "Epoch 441 : Training loss: 0.570473134518, \n",
      " test accuracy : 0.714285731316\n",
      "\n",
      "Epoch 451 : Training loss: 0.589916169643, \n",
      " test accuracy : 0.714285731316\n",
      "\n",
      "Epoch 461 : Training loss: 0.536696195602, \n",
      " test accuracy : 0.714285731316\n",
      "\n",
      "Epoch 471 : Training loss: 0.512100994587, \n",
      " test accuracy : 0.728571414948\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-3c300d3e6dfb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'matplotlib inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_test_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/stanleygan/Documents/NN_pima/model.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, X, y, X_test, y_test, lr, num_epochs, batch_size, seed, printResults, returnResults)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                     \u001b[0;31m#Set up feed_dict for training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                     \u001b[0mfeed_dict_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdo\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mizip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_list_placeholder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dropout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                     \u001b[0mfeed_dict_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_placeholder\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                     \u001b[0mfeed_dict_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_placeholder\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/stanleygan/Documents/NN_pima/model.pyc\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m((ph, do))\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                     \u001b[0;31m#Set up feed_dict for training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                     \u001b[0mfeed_dict_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdo\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mizip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_list_placeholder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dropout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                     \u001b[0mfeed_dict_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_placeholder\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                     \u001b[0mfeed_dict_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_placeholder\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36m__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    562\u001b[0m                                                    self._dtype.name)\n\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 564\u001b[0;31m   \u001b[0;32mdef\u001b[0m \u001b[0m__hash__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m     \u001b[0;31m# Necessary to support Python's collection membership operators\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "mlp.train(X=X_train_scaled, y=y_train, X_test=X_test_scaled, y_test=y_test, num_epochs=5000, lr=0.0001, seed=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation to choose parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'model' from 'model.py'>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import helper\n",
    "import model\n",
    "reload(helper)\n",
    "reload(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter set 1:\n",
      "Cross validation set: 1\n",
      "Accuracy: 0.75\n",
      "Cross validation set: 2\n",
      "Accuracy: 0.728571428571\n",
      "Cross validation set: 3\n",
      "Accuracy: 0.757142857143\n",
      "Cross validation set: 4\n",
      "Accuracy: 0.807142857143\n",
      "Cross validation set: 5\n",
      "Accuracy: 0.804347826087\n",
      "\n",
      "Parameter set 2:\n",
      "Cross validation set: 1\n",
      "Accuracy: 0.7\n",
      "Cross validation set: 2\n",
      "Accuracy: 0.664285714286\n",
      "Cross validation set: 3\n",
      "Accuracy: 0.707142857143\n",
      "Cross validation set: 4\n",
      "Accuracy: 0.75\n",
      "Cross validation set: 5\n",
      "Accuracy: 0.710144927536\n",
      "\n",
      "Parameter set 3:\n",
      "Cross validation set: 1\n",
      "Accuracy: 0.714285714286\n",
      "Cross validation set: 2\n",
      "Accuracy: 0.707142857143\n",
      "Cross validation set: 3\n",
      "Accuracy: 0.685714285714\n",
      "Cross validation set: 4\n",
      "Accuracy: 0.821428571429\n",
      "Cross validation set: 5\n",
      "Accuracy: 0.746376811594\n",
      "\n",
      "Parameter set 4:\n",
      "Cross validation set: 1\n",
      "Accuracy: 0.742857142857\n",
      "Cross validation set: 2\n",
      "Accuracy: 0.721428571429\n",
      "Cross validation set: 3\n",
      "Accuracy: 0.742857142857\n",
      "Cross validation set: 4\n",
      "Accuracy: 0.807142857143\n",
      "Cross validation set: 5\n",
      "Accuracy: 0.768115942029\n",
      "\n",
      "Parameter set 5:\n",
      "Cross validation set: 1\n",
      "Accuracy: 0.764285714286\n",
      "Cross validation set: 2\n",
      "Accuracy: 0.75\n",
      "Cross validation set: 3\n",
      "Accuracy: 0.75\n",
      "Cross validation set: 4\n",
      "Accuracy: 0.8\n",
      "Cross validation set: 5\n",
      "Accuracy: 0.782608695652\n",
      "\n",
      "The best cross validation accuracy is: 0.769440993789\n",
      "The parameters which achieve this accuracy are: \n",
      "0: {'activations': ['relu', 'relu', 'relu'], 'dropout': [0.8, 0.8, 0.8], 'neurons': [30, 20, 10], 'learning_rate': 0.0001}\n"
     ]
    }
   ],
   "source": [
    "neurons=[[30,20,10],\n",
    "         [50,40,30,20,10],\n",
    "         [30,25,20,15],\n",
    "        [50,30,40],\n",
    "        [30,20],\n",
    "        [40,35,30,25,20,15,10],\n",
    "        [20,10,5,3]]\n",
    "\n",
    "activations=[['relu']*3,\n",
    "             ['relu6']*5,\n",
    "             ['relu6']*4,\n",
    "             ['sigmoid']*3,\n",
    "             ['elu']*2,\n",
    "             ['relu6']*7,\n",
    "             ['tanh']*4\n",
    "            ]\n",
    "\n",
    "dropout = [[0.8]*3,\n",
    "           [0.8]*5,\n",
    "           [0.8]*4,\n",
    "           [0.5]*3,\n",
    "           [0.7]*2,\n",
    "           [0.6]*7,\n",
    "           [0.9]*4\n",
    "          ]\n",
    "\n",
    "lr = [0.0001, 0.001, 0.0005, 0.0001, 0.0003]\n",
    "\n",
    "helper.CV_pipeline(X_train_scaled, y_train, neurons, activations, dropout,\n",
    "                   lr, inputDim=X_train_scaled.shape[1], outputDim=2, seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on Full Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 : Training loss: 0.681595921516, \n",
      " test accuracy : 0.657142877579\n",
      "\n",
      "Epoch 11 : Training loss: 0.675879538059, \n",
      " test accuracy : 0.657142877579\n",
      "\n",
      "Epoch 21 : Training loss: 0.658284425735, \n",
      " test accuracy : 0.657142877579\n",
      "\n",
      "Epoch 31 : Training loss: 0.613141655922, \n",
      " test accuracy : 0.671428561211\n",
      "\n",
      "Epoch 41 : Training loss: 0.574695467949, \n",
      " test accuracy : 0.785714268684\n",
      "\n",
      "Epoch 51 : Training loss: 0.492916703224, \n",
      " test accuracy : 0.785714268684\n",
      "\n",
      "Epoch 61 : Training loss: 0.492948234081, \n",
      " test accuracy : 0.785714268684\n",
      "\n",
      "Epoch 71 : Training loss: 0.459458619356, \n",
      " test accuracy : 0.757142841816\n",
      "\n",
      "Epoch 81 : Training loss: 0.445783853531, \n",
      " test accuracy : 0.757142841816\n",
      "\n",
      "Epoch 91 : Training loss: 0.454318463802, \n",
      " test accuracy : 0.757142841816\n",
      "\n",
      "Epoch 101 : Training loss: 0.449540525675, \n",
      " test accuracy : 0.771428585052\n",
      "\n",
      "Epoch 111 : Training loss: 0.449619531631, \n",
      " test accuracy : 0.771428585052\n",
      "\n",
      "Epoch 121 : Training loss: 0.42033919692, \n",
      " test accuracy : 0.771428585052\n",
      "\n",
      "Epoch 131 : Training loss: 0.462801963091, \n",
      " test accuracy : 0.771428585052\n",
      "\n",
      "Epoch 141 : Training loss: 0.425211966038, \n",
      " test accuracy : 0.771428585052\n",
      "\n",
      "Epoch 151 : Training loss: 0.431015372276, \n",
      " test accuracy : 0.785714268684\n",
      "\n",
      "Epoch 161 : Training loss: 0.39061152935, \n",
      " test accuracy : 0.771428585052\n",
      "\n",
      "Epoch 171 : Training loss: 0.410557538271, \n",
      " test accuracy : 0.785714268684\n",
      "\n",
      "Epoch 181 : Training loss: 0.428725123405, \n",
      " test accuracy : 0.771428585052\n",
      "\n",
      "Epoch 191 : Training loss: 0.425719261169, \n",
      " test accuracy : 0.771428585052\n",
      "\n",
      "Epoch 201 : Training loss: 0.463366836309, \n",
      " test accuracy : 0.771428585052\n",
      "\n",
      "Epoch 211 : Training loss: 0.486317127943, \n",
      " test accuracy : 0.785714268684\n",
      "\n",
      "Epoch 221 : Training loss: 0.452462911606, \n",
      " test accuracy : 0.785714268684\n",
      "\n",
      "Epoch 231 : Training loss: 0.424885392189, \n",
      " test accuracy : 0.785714268684\n",
      "\n",
      "Epoch 241 : Training loss: 0.446334421635, \n",
      " test accuracy : 0.771428585052\n",
      "\n",
      "Epoch 251 : Training loss: 0.397943794727, \n",
      " test accuracy : 0.785714268684\n",
      "\n",
      "Epoch 261 : Training loss: 0.424981713295, \n",
      " test accuracy : 0.785714268684\n",
      "\n",
      "Epoch 271 : Training loss: 0.423100113869, \n",
      " test accuracy : 0.785714268684\n",
      "\n",
      "Epoch 281 : Training loss: 0.398465812206, \n",
      " test accuracy : 0.785714268684\n",
      "\n",
      "Epoch 291 : Training loss: 0.35903403163, \n",
      " test accuracy : 0.785714268684\n",
      "\n",
      "Epoch 301 : Training loss: 0.385866522789, \n",
      " test accuracy : 0.785714268684\n",
      "\n",
      "Epoch 311 : Training loss: 0.418215513229, \n",
      " test accuracy : 0.785714268684\n",
      "\n",
      "Epoch 321 : Training loss: 0.421074032784, \n",
      " test accuracy : 0.785714268684\n",
      "\n",
      "Epoch 331 : Training loss: 0.392260193825, \n",
      " test accuracy : 0.785714268684\n",
      "\n",
      "Epoch 341 : Training loss: 0.390774905682, \n",
      " test accuracy : 0.785714268684\n",
      "\n",
      "Epoch 351 : Training loss: 0.389129340649, \n",
      " test accuracy : 0.785714268684\n",
      "\n",
      "Epoch 361 : Training loss: 0.365542948246, \n",
      " test accuracy : 0.785714268684\n",
      "\n",
      "Epoch 371 : Training loss: 0.382115900517, \n",
      " test accuracy : 0.785714268684\n",
      "\n",
      "Epoch 381 : Training loss: 0.371410280466, \n",
      " test accuracy : 0.771428585052\n",
      "\n",
      "Epoch 391 : Training loss: 0.43731161952, \n",
      " test accuracy : 0.771428585052\n",
      "\n",
      "Epoch 401 : Training loss: 0.363954514265, \n",
      " test accuracy : 0.785714268684\n",
      "\n",
      "Epoch 411 : Training loss: 0.380887985229, \n",
      " test accuracy : 0.771428585052\n",
      "\n",
      "Epoch 421 : Training loss: 0.403491377831, \n",
      " test accuracy : 0.771428585052\n",
      "\n",
      "Epoch 431 : Training loss: 0.395797848701, \n",
      " test accuracy : 0.771428585052\n",
      "\n",
      "Epoch 441 : Training loss: 0.341929376125, \n",
      " test accuracy : 0.785714268684\n",
      "\n",
      "Epoch 451 : Training loss: 0.397901713848, \n",
      " test accuracy : 0.785714268684\n",
      "\n",
      "Epoch 461 : Training loss: 0.416732728481, \n",
      " test accuracy : 0.785714268684\n",
      "\n",
      "Epoch 471 : Training loss: 0.460156738758, \n",
      " test accuracy : 0.771428585052\n",
      "\n",
      "Epoch 481 : Training loss: 0.383755415678, \n",
      " test accuracy : 0.785714268684\n",
      "\n",
      "Epoch 491 : Training loss: 0.39243093133, \n",
      " test accuracy : 0.771428585052\n",
      "\n",
      "Epoch 501 : Training loss: 0.34617036581, \n",
      " test accuracy : 0.771428585052\n",
      "\n",
      "Epoch 511 : Training loss: 0.402512311935, \n",
      " test accuracy : 0.771428585052\n",
      "\n",
      "Epoch 521 : Training loss: 0.408170461655, \n",
      " test accuracy : 0.771428585052\n",
      "\n",
      "Epoch 531 : Training loss: 0.4187682271, \n",
      " test accuracy : 0.771428585052\n",
      "\n",
      "Epoch 541 : Training loss: 0.345293909311, \n",
      " test accuracy : 0.771428585052\n",
      "\n",
      "Epoch 551 : Training loss: 0.388815611601, \n",
      " test accuracy : 0.771428585052\n",
      "\n",
      "Epoch 561 : Training loss: 0.388752490282, \n",
      " test accuracy : 0.771428585052\n",
      "\n",
      "Epoch 571 : Training loss: 0.407780528069, \n",
      " test accuracy : 0.771428585052\n",
      "\n",
      "Epoch 581 : Training loss: 0.384679168463, \n",
      " test accuracy : 0.771428585052\n",
      "\n",
      "Epoch 591 : Training loss: 0.349815756083, \n",
      " test accuracy : 0.757142841816\n",
      "\n",
      "Epoch 601 : Training loss: 0.340648323298, \n",
      " test accuracy : 0.771428585052\n",
      "\n",
      "Epoch 611 : Training loss: 0.422310858965, \n",
      " test accuracy : 0.757142841816\n",
      "\n",
      "Epoch 621 : Training loss: 0.384790360928, \n",
      " test accuracy : 0.771428585052\n",
      "\n",
      "Epoch 631 : Training loss: 0.424626231194, \n",
      " test accuracy : 0.757142841816\n",
      "\n",
      "Epoch 641 : Training loss: 0.352756738663, \n",
      " test accuracy : 0.757142841816\n",
      "\n",
      "Epoch 651 : Training loss: 0.325002759695, \n",
      " test accuracy : 0.757142841816\n",
      "\n",
      "Epoch 661 : Training loss: 0.405796647072, \n",
      " test accuracy : 0.757142841816\n",
      "\n",
      "Epoch 671 : Training loss: 0.355532616377, \n",
      " test accuracy : 0.757142841816\n",
      "\n",
      "Epoch 681 : Training loss: 0.382972717285, \n",
      " test accuracy : 0.757142841816\n",
      "\n",
      "Epoch 691 : Training loss: 0.373289465904, \n",
      " test accuracy : 0.757142841816\n",
      "\n",
      "Epoch 701 : Training loss: 0.357721954584, \n",
      " test accuracy : 0.757142841816\n",
      "\n",
      "Epoch 711 : Training loss: 0.361226439476, \n",
      " test accuracy : 0.757142841816\n",
      "\n",
      "Epoch 721 : Training loss: 0.395128667355, \n",
      " test accuracy : 0.757142841816\n",
      "\n",
      "Epoch 731 : Training loss: 0.362058460712, \n",
      " test accuracy : 0.757142841816\n",
      "\n",
      "Epoch 741 : Training loss: 0.331292867661, \n",
      " test accuracy : 0.757142841816\n",
      "\n",
      "Epoch 751 : Training loss: 0.337878882885, \n",
      " test accuracy : 0.757142841816\n",
      "\n",
      "Epoch 761 : Training loss: 0.412265330553, \n",
      " test accuracy : 0.757142841816\n",
      "\n",
      "Epoch 771 : Training loss: 0.34564229846, \n",
      " test accuracy : 0.757142841816\n",
      "\n",
      "Epoch 781 : Training loss: 0.386102557182, \n",
      " test accuracy : 0.757142841816\n",
      "\n",
      "Epoch 791 : Training loss: 0.415094941854, \n",
      " test accuracy : 0.757142841816\n",
      "\n",
      "Epoch 801 : Training loss: 0.359878093004, \n",
      " test accuracy : 0.757142841816\n",
      "\n",
      "Epoch 811 : Training loss: 0.339470624924, \n",
      " test accuracy : 0.757142841816\n",
      "\n",
      "Epoch 821 : Training loss: 0.387715131044, \n",
      " test accuracy : 0.757142841816\n",
      "\n",
      "Epoch 831 : Training loss: 0.339167237282, \n",
      " test accuracy : 0.757142841816\n",
      "\n",
      "Epoch 841 : Training loss: 0.412250339985, \n",
      " test accuracy : 0.757142841816\n",
      "\n",
      "Epoch 851 : Training loss: 0.338279515505, \n",
      " test accuracy : 0.757142841816\n",
      "\n",
      "Epoch 861 : Training loss: 0.330316483974, \n",
      " test accuracy : 0.757142841816\n",
      "\n",
      "Epoch 871 : Training loss: 0.366371691227, \n",
      " test accuracy : 0.757142841816\n",
      "\n",
      "Epoch 881 : Training loss: 0.397398173809, \n",
      " test accuracy : 0.757142841816\n",
      "\n",
      "Epoch 891 : Training loss: 0.34015199542, \n",
      " test accuracy : 0.771428585052\n",
      "\n",
      "Epoch 901 : Training loss: 0.360235571861, \n",
      " test accuracy : 0.771428585052\n",
      "\n",
      "Epoch 911 : Training loss: 0.361537486315, \n",
      " test accuracy : 0.757142841816\n",
      "\n",
      "Epoch 921 : Training loss: 0.344079434872, \n",
      " test accuracy : 0.757142841816\n",
      "\n",
      "Epoch 931 : Training loss: 0.342257708311, \n",
      " test accuracy : 0.771428585052\n",
      "\n",
      "Epoch 941 : Training loss: 0.319759637117, \n",
      " test accuracy : 0.757142841816\n",
      "\n",
      "Epoch 951 : Training loss: 0.325826883316, \n",
      " test accuracy : 0.771428585052\n",
      "\n",
      "Epoch 961 : Training loss: 0.309854745865, \n",
      " test accuracy : 0.785714268684\n",
      "\n",
      "Epoch 971 : Training loss: 0.353979229927, \n",
      " test accuracy : 0.757142841816\n",
      "\n",
      "Epoch 981 : Training loss: 0.308914780617, \n",
      " test accuracy : 0.771428585052\n",
      "\n",
      "Epoch 991 : Training loss: 0.34972345829, \n",
      " test accuracy : 0.785714268684\n",
      "\n",
      "Epoch 1001 : Training loss: 0.314413607121, \n",
      " test accuracy : 0.785714268684\n",
      "\n",
      "Epoch 1011 : Training loss: 0.36461609602, \n",
      " test accuracy : 0.785714268684\n",
      "\n",
      "Epoch 1021 : Training loss: 0.31182706356, \n",
      " test accuracy : 0.771428585052\n",
      "\n",
      "Epoch 1031 : Training loss: 0.358142495155, \n",
      " test accuracy : 0.785714268684\n",
      "\n",
      "Epoch 1041 : Training loss: 0.334685355425, \n",
      " test accuracy : 0.785714268684\n",
      "\n",
      "Epoch 1051 : Training loss: 0.37632843852, \n",
      " test accuracy : 0.785714268684\n",
      "\n",
      "Epoch 1061 : Training loss: 0.345504134893, \n",
      " test accuracy : 0.785714268684\n",
      "\n",
      "Epoch 1071 : Training loss: 0.351514399052, \n",
      " test accuracy : 0.785714268684\n",
      "\n",
      "Epoch 1081 : Training loss: 0.26642459631, \n",
      " test accuracy : 0.785714268684\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1091 : Training loss: 0.32111954689, \n",
      " test accuracy : 0.785714268684\n",
      "\n",
      "Epoch 1101 : Training loss: 0.279783308506, \n",
      " test accuracy : 0.785714268684\n",
      "\n",
      "Epoch 1111 : Training loss: 0.331587821245, \n",
      " test accuracy : 0.785714268684\n",
      "\n",
      "Epoch 1121 : Training loss: 0.318917542696, \n",
      " test accuracy : 0.785714268684\n",
      "\n",
      "Epoch 1131 : Training loss: 0.318982064724, \n",
      " test accuracy : 0.785714268684\n",
      "\n",
      "Epoch 1141 : Training loss: 0.297131299973, \n",
      " test accuracy : 0.785714268684\n",
      "\n",
      "Epoch 1151 : Training loss: 0.330166041851, \n",
      " test accuracy : 0.757142841816\n",
      "\n",
      "Epoch 1161 : Training loss: 0.307197034359, \n",
      " test accuracy : 0.785714268684\n",
      "\n",
      "Epoch 1171 : Training loss: 0.344839096069, \n",
      " test accuracy : 0.771428585052\n",
      "\n",
      "Epoch 1181 : Training loss: 0.318485081196, \n",
      " test accuracy : 0.785714268684\n",
      "\n",
      "Epoch 1191 : Training loss: 0.326407700777, \n",
      " test accuracy : 0.757142841816\n",
      "\n",
      "Epoch 1201 : Training loss: 0.328310400248, \n",
      " test accuracy : 0.757142841816\n",
      "\n",
      "Epoch 1211 : Training loss: 0.313116341829, \n",
      " test accuracy : 0.771428585052\n",
      "\n",
      "Epoch 1221 : Training loss: 0.311994373798, \n",
      " test accuracy : 0.800000011921\n",
      "\n",
      "Epoch 1231 : Training loss: 0.296829253435, \n",
      " test accuracy : 0.771428585052\n",
      "\n",
      "Epoch 1241 : Training loss: 0.350113511086, \n",
      " test accuracy : 0.771428585052\n",
      "\n",
      "Epoch 1251 : Training loss: 0.323261857033, \n",
      " test accuracy : 0.785714268684\n",
      "\n",
      "Epoch 1261 : Training loss: 0.281539976597, \n",
      " test accuracy : 0.785714268684\n",
      "\n",
      "Epoch 1271 : Training loss: 0.317996770144, \n",
      " test accuracy : 0.771428585052\n",
      "\n",
      "Epoch 1281 : Training loss: 0.303452074528, \n",
      " test accuracy : 0.757142841816\n",
      "\n",
      "Epoch 1291 : Training loss: 0.34521573782, \n",
      " test accuracy : 0.757142841816\n",
      "\n",
      "Epoch 1301 : Training loss: 0.363956093788, \n",
      " test accuracy : 0.785714268684\n",
      "\n",
      "Epoch 1311 : Training loss: 0.281059831381, \n",
      " test accuracy : 0.771428585052\n",
      "\n",
      "Epoch 1321 : Training loss: 0.291898995638, \n",
      " test accuracy : 0.785714268684\n",
      "\n",
      "Epoch 1331 : Training loss: 0.34954097867, \n",
      " test accuracy : 0.771428585052\n",
      "\n",
      "Epoch 1341 : Training loss: 0.294068872929, \n",
      " test accuracy : 0.771428585052\n",
      "\n",
      "Epoch 1351 : Training loss: 0.403645813465, \n",
      " test accuracy : 0.757142841816\n",
      "\n",
      "Epoch 1361 : Training loss: 0.331594765186, \n",
      " test accuracy : 0.757142841816\n",
      "\n",
      "Epoch 1371 : Training loss: 0.33153116703, \n",
      " test accuracy : 0.757142841816\n",
      "\n",
      "Epoch 1381 : Training loss: 0.289124250412, \n",
      " test accuracy : 0.742857158184\n",
      "\n",
      "Epoch 1391 : Training loss: 0.334737479687, \n",
      " test accuracy : 0.742857158184\n",
      "\n",
      "Epoch 1401 : Training loss: 0.237714037299, \n",
      " test accuracy : 0.742857158184\n",
      "\n",
      "Epoch 1411 : Training loss: 0.316319525242, \n",
      " test accuracy : 0.757142841816\n",
      "\n",
      "Epoch 1421 : Training loss: 0.344746917486, \n",
      " test accuracy : 0.757142841816\n",
      "\n",
      "Epoch 1431 : Training loss: 0.321398973465, \n",
      " test accuracy : 0.757142841816\n",
      "\n",
      "Epoch 1441 : Training loss: 0.310266196728, \n",
      " test accuracy : 0.757142841816\n",
      "\n",
      "Epoch 1451 : Training loss: 0.255263119936, \n",
      " test accuracy : 0.771428585052\n",
      "\n",
      "Epoch 1461 : Training loss: 0.301509231329, \n",
      " test accuracy : 0.771428585052\n",
      "\n",
      "Epoch 1471 : Training loss: 0.333456367254, \n",
      " test accuracy : 0.785714268684\n",
      "\n",
      "Epoch 1481 : Training loss: 0.2943572402, \n",
      " test accuracy : 0.771428585052\n",
      "\n",
      "Epoch 1491 : Training loss: 0.332651823759, \n",
      " test accuracy : 0.771428585052\n",
      "\n",
      "Epoch 1501 : Training loss: 0.270468324423, \n",
      " test accuracy : 0.771428585052\n",
      "\n",
      "Epoch 1511 : Training loss: 0.275341063738, \n",
      " test accuracy : 0.771428585052\n",
      "\n",
      "Epoch 1521 : Training loss: 0.322981953621, \n",
      " test accuracy : 0.771428585052\n",
      "\n",
      "Epoch 1531 : Training loss: 0.285512238741, \n",
      " test accuracy : 0.771428585052\n",
      "\n",
      "Epoch 1541 : Training loss: 0.258943796158, \n",
      " test accuracy : 0.771428585052\n",
      "\n",
      "Epoch 1551 : Training loss: 0.34257760644, \n",
      " test accuracy : 0.771428585052\n",
      "\n",
      "Epoch 1561 : Training loss: 0.243120878935, \n",
      " test accuracy : 0.771428585052\n",
      "\n",
      "Epoch 1571 : Training loss: 0.286564856768, \n",
      " test accuracy : 0.771428585052\n",
      "\n",
      "Epoch 1581 : Training loss: 0.251077413559, \n",
      " test accuracy : 0.771428585052\n",
      "\n",
      "Epoch 1591 : Training loss: 0.289470106363, \n",
      " test accuracy : 0.771428585052\n",
      "\n",
      "Epoch 1601 : Training loss: 0.259000062943, \n",
      " test accuracy : 0.771428585052\n",
      "\n",
      "Epoch 1611 : Training loss: 0.299342513084, \n",
      " test accuracy : 0.771428585052\n",
      "\n",
      "Epoch 1621 : Training loss: 0.316435456276, \n",
      " test accuracy : 0.771428585052\n",
      "\n",
      "Epoch 1631 : Training loss: 0.277167439461, \n",
      " test accuracy : 0.785714268684\n",
      "\n",
      "Epoch 1641 : Training loss: 0.29672768712, \n",
      " test accuracy : 0.785714268684\n",
      "\n",
      "Epoch 1651 : Training loss: 0.293793767691, \n",
      " test accuracy : 0.771428585052\n",
      "\n",
      "Epoch 1661 : Training loss: 0.341704696417, \n",
      " test accuracy : 0.771428585052\n",
      "\n",
      "Epoch 1671 : Training loss: 0.26507845521, \n",
      " test accuracy : 0.757142841816\n",
      "\n",
      "Epoch 1681 : Training loss: 0.315107554197, \n",
      " test accuracy : 0.771428585052\n",
      "\n",
      "Epoch 1691 : Training loss: 0.286018639803, \n",
      " test accuracy : 0.771428585052\n",
      "\n",
      "Epoch 1701 : Training loss: 0.279402703047, \n",
      " test accuracy : 0.771428585052\n",
      "\n",
      "Epoch 1711 : Training loss: 0.261170655489, \n",
      " test accuracy : 0.771428585052\n",
      "\n",
      "Epoch 1721 : Training loss: 0.305893689394, \n",
      " test accuracy : 0.771428585052\n",
      "\n",
      "Epoch 1731 : Training loss: 0.256539434195, \n",
      " test accuracy : 0.771428585052\n",
      "\n",
      "Epoch 1741 : Training loss: 0.276951372623, \n",
      " test accuracy : 0.785714268684\n",
      "\n",
      "Epoch 1751 : Training loss: 0.316247880459, \n",
      " test accuracy : 0.771428585052\n",
      "\n",
      "Epoch 1761 : Training loss: 0.290902554989, \n",
      " test accuracy : 0.771428585052\n",
      "\n",
      "Epoch 1771 : Training loss: 0.311096161604, \n",
      " test accuracy : 0.785714268684\n",
      "\n",
      "Epoch 1781 : Training loss: 0.258496820927, \n",
      " test accuracy : 0.785714268684\n",
      "\n",
      "Epoch 1791 : Training loss: 0.275920808315, \n",
      " test accuracy : 0.771428585052\n",
      "\n",
      "Epoch 1801 : Training loss: 0.222266703844, \n",
      " test accuracy : 0.800000011921\n",
      "\n",
      "Epoch 1811 : Training loss: 0.254874259233, \n",
      " test accuracy : 0.785714268684\n",
      "\n",
      "Epoch 1821 : Training loss: 0.268807858229, \n",
      " test accuracy : 0.785714268684\n",
      "\n",
      "Epoch 1831 : Training loss: 0.312947511673, \n",
      " test accuracy : 0.785714268684\n",
      "\n",
      "Epoch 1841 : Training loss: 0.284669101238, \n",
      " test accuracy : 0.771428585052\n",
      "\n",
      "Epoch 1851 : Training loss: 0.235213905573, \n",
      " test accuracy : 0.785714268684\n",
      "\n",
      "Epoch 1861 : Training loss: 0.304343193769, \n",
      " test accuracy : 0.785714268684\n",
      "\n",
      "Epoch 1871 : Training loss: 0.273419648409, \n",
      " test accuracy : 0.785714268684\n",
      "\n",
      "Epoch 1881 : Training loss: 0.282349407673, \n",
      " test accuracy : 0.785714268684\n",
      "\n",
      "Epoch 1891 : Training loss: 0.329395055771, \n",
      " test accuracy : 0.785714268684\n",
      "\n",
      "Epoch 1901 : Training loss: 0.230541855097, \n",
      " test accuracy : 0.785714268684\n",
      "\n",
      "Epoch 1911 : Training loss: 0.341271489859, \n",
      " test accuracy : 0.771428585052\n",
      "\n",
      "Epoch 1921 : Training loss: 0.22001105547, \n",
      " test accuracy : 0.785714268684\n",
      "\n",
      "Epoch 1931 : Training loss: 0.232033625245, \n",
      " test accuracy : 0.785714268684\n",
      "\n",
      "Epoch 1941 : Training loss: 0.255322396755, \n",
      " test accuracy : 0.785714268684\n",
      "\n",
      "Epoch 1951 : Training loss: 0.281358659267, \n",
      " test accuracy : 0.785714268684\n",
      "\n",
      "Epoch 1961 : Training loss: 0.264796406031, \n",
      " test accuracy : 0.771428585052\n",
      "\n",
      "Epoch 1971 : Training loss: 0.268742799759, \n",
      " test accuracy : 0.771428585052\n",
      "\n",
      "Epoch 1981 : Training loss: 0.266627401114, \n",
      " test accuracy : 0.771428585052\n",
      "\n",
      "Epoch 1991 : Training loss: 0.270287007093, \n",
      " test accuracy : 0.785714268684\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5860b3c050>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inputDim = X_train_scaled.shape[1]\n",
    "outputDim = y_train.shape[1]\n",
    "mlp = MLP()\n",
    "mlp.buildModel(neurons=[30,20,10], activations=['relu', 'relu', 'relu'], \n",
    "               dropout=[0.8,0.8, 0.8], inputDim=inputDim, outputDim=outputDim)\n",
    "\n",
    "%matplotlib inline\n",
    "results = mlp.train(X=X_train_scaled, y=y_train, X_test=X_test_scaled, y_test=y_test, \n",
    "                    num_epochs=2000, lr=0.0003, seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on each test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict on each scaled test set and obtain average accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average accuracy on imputed test sets: 0.785714285714\n"
     ]
    }
   ],
   "source": [
    "accuracy_list = list()\n",
    "\n",
    "for ts in test_split_list:\n",
    "    temp_scaled = scale_X.transform(ts[0])\n",
    "    res = mlp.predict(X=temp_scaled, seed=seed)\n",
    "    accuracy = (res[\"y_pred_cls\"][:,0] == ts[1][:,0]).sum() / float(len(res[\"y_pred_cls\"]))\n",
    "    accuracy_list.append(accuracy)\n",
    "    \n",
    "print(\"The average accuracy on imputed test sets: {}\".format(np.mean(accuracy_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7857142857142857,\n",
       " 0.7857142857142857,\n",
       " 0.7857142857142857,\n",
       " 0.7857142857142857,\n",
       " 0.7857142857142857]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA is often used as a dimensionality reduction method in machine learning. In this project, I would like to use sparse PCA, a variant of PCA which sets a constraint on the number of features used to produce the PCs. Sparse PCA minimizes the number of features used in producing the PCs. Use cross validation to choose number of components. **Other parameters such as shrinkage parameter and sparsity can be chosen using CV but currently not supported **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
